{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4042886304.py, line 220)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 220\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install -U scikit-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "trades = pd.read_excel(r'invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "trades.columns\n",
    "\n",
    "trades\n",
    "\n",
    "trades.groupby('Dealer').agg({'ISIN':'count','Screen saving (price)': 'mean','Accepted Vol':'mean'})\n",
    "\n",
    "\n",
    "trades.groupby('Dealer').agg({'ISIN':'count','Screen saving (price)': 'mean'}).sort_values(by = 'Screen saving (price)')\n",
    "\n",
    "trades[trades.Dealer =='DB']\n",
    "\n",
    "# Drop rows with missing values\n",
    "trades.dropna(subset=['Dealer', 'Screen Saving (amount)'], inplace=True)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['Time To Quote', 'Accepted Vol']\n",
    "\n",
    "# Create a dictionary to store cheapest screen saving amounts for each dealer\n",
    "dealer_cheapest_amounts = {}\n",
    "\n",
    "# Iterate over unique dealers\n",
    "for dealer in trades['Dealer'].unique():\n",
    "   # Filter data for the specific dealer\n",
    "   dealer_data = trades[trades['Dealer'] == dealer]\n",
    "\n",
    "   # Check if the dealer has sufficient data points\n",
    "   if len(dealer_data) > 1:  # At least 2 data points are required for splitting\n",
    "       # Separate features and target variable\n",
    "       X = dealer_data[feature_columns]\n",
    "       y = dealer_data['Screen Saving (amount)']\n",
    "\n",
    "       # Split the data into training and testing sets\n",
    "       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "       # Create a transformer for numerical features\n",
    "       numerical_transformer = StandardScaler()\n",
    "\n",
    "       # Create a pipeline for numerical features\n",
    "       numerical_pipeline = Pipeline(steps=[\n",
    "           ('num', numerical_transformer)\n",
    "       ])\n",
    "\n",
    "       # Fit and transform the numerical features\n",
    "       X_train_numerical = numerical_pipeline.fit_transform(X_train)\n",
    "       X_test_numerical = numerical_pipeline.transform(X_test)\n",
    "\n",
    "       # Create an XGBoost regressor for amount prediction\n",
    "       xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "       # Fit the XGBoost model\n",
    "       xgb_regressor.fit(X_train_numerical, y_train)\n",
    "\n",
    "       # Make predictions on the test data\n",
    "       y_pred = xgb_regressor.predict(X_test_numerical)\n",
    "\n",
    "       # Calculate the cheapest screen saving amount for the dealer\n",
    "       cheapest_amount = np.min(y_pred)\n",
    "       dealer_cheapest_amounts[dealer] = cheapest_amount\n",
    "\n",
    "# Rank dealers based on cheapest amounts\n",
    "ranked_dealers = sorted(dealer_cheapest_amounts, key=lambda x: dealer_cheapest_amounts[x])\n",
    "\n",
    "# Print ranked dealers\n",
    "for rank, dealer in enumerate(ranked_dealers, start=1):\n",
    "   print(f\"Rank {rank}: Dealer '{dealer}' with cheapest amount of {dealer_cheapest_amounts[dealer]}\")\n",
    "\n",
    "# Create a transformer for numerical features\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Transform all data for permutation importance\n",
    "X_numerical = numerical_transformer.fit_transform(trades[feature_columns])\n",
    "y_amount = trades['Screen Saving (amount)']\n",
    "\n",
    "\n",
    "# Create an XGBoost regressor for amount prediction\n",
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_regressor.fit(X_numerical, y_amount)\n",
    "\n",
    "from sklearn.inspection import permutation_importance  # Add this import\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.inspection import permutation_importance  # Add this import\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xisx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing values\n",
    "trades.dropna(subset=['Dealer', 'Screen saving (amount)', 'Time To Quote', 'Accepted Vol'], inplace=True)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['Time To Quote', 'Accepted Vol']\n",
    "\n",
    "# Separate features and target variable\n",
    "X = trades[feature_columns]\n",
    "y = trades['Screen saving (amount)']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a transformer for numerical features\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "   ('num', numerical_transformer)\n",
    "])\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "X_train_numerical = numerical_pipeline.fit_transform(X_train)\n",
    "X_test_numerical = numerical_pipeline.transform(X_test)\n",
    "\n",
    "# Create an XGBoost regressor for amount prediction\n",
    "xgb_regressor = xgb.XGBRegressor(\n",
    "   objective='reg:squarederror',\n",
    "   random_state=42,\n",
    "   n_estimators=1000,\n",
    "   learning_rate=0.1,\n",
    "   max_depth=5,\n",
    "   min_child_weight=1,\n",
    "   gamma=0,\n",
    "   subsample=0.8,\n",
    "   colsample_bytree=0.8,\n",
    "   verbosity=0\n",
    ")\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_regressor.fit(X_train_numerical, y_train)\n",
    "\n",
    "# Create and display partial dependence plots\n",
    "plot_partial_dependence(xgb_regressor, X_train_numerical, features=[1], grid_resolution=50)  # 1 corresponds to \"Accepted Vol\"\n",
    "plt.show()\n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(xgb_regressor, X_train_numerical, y_train, n_repeats=30, random_state=42)\n",
    "\n",
    "pip install -U scikit-learn \n",
    "\n",
    "# Calculate permutation importance\n",
    "perm_importance = permutation_importance(xgb_regressor, X_numerical, y_amount, n_repeats=30, random_state=42)\n",
    "\n",
    "# Print permutation importance scores\n",
    "for i, feature in enumerate(feature_columns):\n",
    "   print(f'{feature} importance: {perm_importance.importances_mean[i]}')\n",
    "\n",
    "# Plot permutation importance scores using Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=perm_importance.importances_mean, y=feature_columns)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Permutation Importance for Predicting Cheapest Amount')\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing values\n",
    "trades.dropna(subset=['Dealer', 'Screen Saving (amount)'], inplace=True)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['Time To Quote', 'Accepted Vol']\n",
    "\n",
    "# Create a dictionary to store cheapest screen saving amounts for each dealer\n",
    "dealer_cheapest_amounts = {}\n",
    "\n",
    "# Iterate over unique dealers\n",
    "for dealer in trades['Dealer'].unique():\n",
    "   # Filter data for the specific dealer\n",
    "   dealer_data = trades[trades['Dealer'] == dealer]\n",
    "\n",
    "   # Check if the dealer has sufficient data points\n",
    "   if len(dealer_data) > 1:  # At least 2 data points are required for splitting\n",
    "       # Separate features and target variable\n",
    "       X = dealer_data[feature_columns]\n",
    "       y = dealer_data['Screen Saving (amount)']\n",
    "\n",
    "       # Split the data into training and testing sets\n",
    "       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "       # Create a transformer for numerical features\n",
    "       numerical_transformer = StandardScaler()\n",
    "\n",
    "       # Create a pipeline for numerical features\n",
    "       numerical_pipeline = Pipeline(steps=[\n",
    "           ('num', numerical_transformer)\n",
    "       ])\n",
    "\n",
    "       # Fit and transform the numerical features\n",
    "       X_train_numerical = numerical_pipeline.fit_transform(X_train)\n",
    "       X_test_numerical = numerical_pipeline.transform(X_test)\n",
    "\n",
    "       # Create an XGBoost regressor for amount prediction\n",
    "       xgb_regressor = xgb.XGBRegressor(\n",
    "           objective='reg:squarederror',\n",
    "           random_state=42,\n",
    "           n_estimators=1000,  # Set a large number of estimators\n",
    "           learning_rate=0.1,  # Initial learning rate\n",
    "           max_depth=5,        # Example hyperparameters, tune these\n",
    "           min_child_weight=1,\n",
    "           gamma=0,\n",
    "           subsample=0.8,\n",
    "           colsample_bytree=0.8,\n",
    "           verbosity=0\n",
    "       )\n",
    "\n",
    "       # Fit the XGBoost model\n",
    "       xgb_regressor.fit(X_train_numerical, y_train)\n",
    "\n",
    "       # Make predictions on the test data\n",
    "       y_pred = xgb_regressor.predict(X_test_numerical)\n",
    "\n",
    "       # Calculate the cheapest screen saving amount for the dealer\n",
    "       cheapest_amount = np.min(y_pred)\n",
    "       dealer_cheapest_amounts[dealer] = cheapest_amount\n",
    "\n",
    "# Rank dealers based on cheapest amounts\n",
    "ranked_dealers = sorted(dealer_cheapest_amounts, key=lambda x: dealer_cheapest_amounts[x])\n",
    "\n",
    "# Print ranked dealers\n",
    "for rank, dealer in enumerate(ranked_dealers, start=1):\n",
    "   print(f\"Rank {rank}: Dealer '{dealer}' with cheapest amount of {dealer_cheapest_amounts[dealer]}\")\n",
    "\n",
    "# Fit XGBoost model on all data for permutation importance\n",
    "X_numerical = numerical_pipeline.transform(trades[feature_columns])\n",
    "y_amount = trades['Screen Saving (amount)']\n",
    "\n",
    "xgb_regressor.fit(X_numerical, y_amount)\n",
    "\n",
    "# Calculate permutation importance using eli5\n",
    "perm_importance = PermutationImportance(xgb_regressor, random_state=42).fit(X_numerical, y_amount)\n",
    "\n",
    "# Display permutation importance using eli5\n",
    "eli5.show_weights(perm_importance, feature_names=feature_columns)\n",
    "\n",
    "\n",
    "# We measure the amount of randomness in our permutation importance calculation by repeating the process with multiple shuffles. The number after the Â± measures how performance varied from one-reshuffling to the next.\n",
    "\n",
    "# While feature importance shows what variables most affect predictions, partial dependence plots show how a feature affects predictions.\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing values\n",
    "trades.dropna(subset=['Dealer', 'Screen saving (amount)', 'Time To Quote', 'Accepted Vol'], inplace=True)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = ['Time To Quote', 'Accepted Vol']\n",
    "\n",
    "# Separate features and target variable\n",
    "X = trades[feature_columns]\n",
    "y = trades['Screen saving (amount)']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a transformer for numerical features\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Create a pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "   ('num', numerical_transformer)\n",
    "])\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "X_train_numerical = numerical_pipeline.fit_transform(X_train)\n",
    "X_test_numerical = numerical_pipeline.transform(X_test)\n",
    "\n",
    "# Create an XGBoost regressor for amount prediction\n",
    "xgb_regressor = xgb.XGBRegressor(\n",
    "   objective='reg:squarederror',\n",
    "   random_state=42,\n",
    "   n_estimators=1000,\n",
    "   learning_rate=0.1,\n",
    "   max_depth=5,\n",
    "   min_child_weight=1,\n",
    "   gamma=0,\n",
    "   subsample=0.8,\n",
    "   colsample_bytree=0.8,\n",
    "   verbosity=0\n",
    ")\n",
    "\n",
    "# Fit the XGBoost model\n",
    "xgb_regressor.fit(X_train_numerical, y_train)\n",
    "\n",
    "# Create and display partial dependence plots\n",
    "plot_partial_dependence(xgb_regressor, X_train_numerical, features=[1], grid_resolution=50)  # 1 corresponds to \"Accepted Vol\"\n",
    "plt.show()\n",
    "\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "pip install plot_partial_dependence\n",
    "\n",
    "pip install -U scikit-learn --user\n",
    "\n",
    "pip install --upgrade scikit-learn\n",
    "\n",
    "trades.iloc[0]\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing 'Dealer' values\n",
    "trades = trades.dropna(subset=['Dealer'])\n",
    "\n",
    "# Create a countplot using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Dealer', data=trades, order=trades['Dealer'].value_counts().index)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Dealer')\n",
    "plt.ylabel('Number of Trades')\n",
    "plt.title('Number of Trades per Dealer')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing 'Dealer' values\n",
    "trades = trades.dropna(subset=['Dealer'])\n",
    "\n",
    "# Create a scatter plot using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Cover Price', y='Dealer', data=trades)\n",
    "plt.xlabel('Screen Saving Amount')\n",
    "plt.ylabel('Dealer')\n",
    "plt.title('Screen Saving Amount vs. Dealer')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing 'Sector' and 'Accepted Vol' values\n",
    "trades = trades.dropna(subset=['Sector', 'Accepted Vol'])\n",
    "\n",
    "# Group the data by sector and sum the accepted volume\n",
    "sector_accepted_vol = trades.groupby('Sector')['Accepted Vol'].sum()\n",
    "\n",
    "# Create a pie chart using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.pie(sector_accepted_vol, labels=sector_accepted_vol.index, autopct='%1.1f%%', startangle=140)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Distribution of Accepted Volume by Sector')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "trades = pd.read_excel('invesco_complete.xlsx', engine='openpyxl')\n",
    "\n",
    "# Drop rows with missing 'Sector' and 'Accepted Vol' values\n",
    "trades = trades.dropna(subset=['Sector', 'Accepted Vol'])\n",
    "\n",
    "# Group the data by sector and sum the accepted volume\n",
    "sector_accepted_vol = trades.groupby('Sector')['Accepted Vol'].sum()\n",
    "\n",
    "# Create a pie chart using Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = sns.color_palette('pastel')\n",
    "plt.pie(sector_accepted_vol, labels=sector_accepted_vol.index, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Distribution of Accepted Volume by Sector')\n",
    "\n",
    "# Add a legend with colors and descriptions\n",
    "legend_labels = [f'{sector} ({vol:.1f}M)' for sector, vol in zip(sector_accepted_vol.index, sector_accepted_vol / 1e6)]\n",
    "plt.legend(legend_labels, title='Sectors', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
